% filepath: /home/uhc-312/Code/My_Projects/School/DAA-Final-Project/report/greedy/greedy_report.tex
\documentclass[12pt,a4paper]{article}
\usepackage[utf-8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{listings}
\usepackage{geometry}

\geometry{margin=1in}

\theoremstyle{definition}
\newtheorem{definition}{Definición}[section]
\newtheorem{theorem}{Teorema}[section]
\newtheorem{lemma}{Lema}[section]
\newtheorem{corollary}{Corolario}[section]
\newtheorem{proposition}{Proposición}[section]

\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{red},
    breaklines=true,
    tabsize=4
}

\title{Informe Técnico: Algoritmo Greedy para\\el Problema de Selección Óptima de Talento}
\author{Análisis, Garantías de Aproximación y Complejidad}
\date{\today}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{Introducción}

En este informe se presenta un análisis formal del algoritmo \textbf{Greedy (Codicioso)} implementado para resolver el problema de selección óptima de talento. A diferencia del algoritmo de backtracking que garantiza optimalidad, el greedy es un algoritmo de \textbf{aproximación} que intercambia optimalidad por eficiencia computacional.

El algoritmo greedy implementa una estrategia simple pero efectiva: en cada iteración, selecciona el empleado con la mejor relación \textbf{costo-efectividad}, es decir, aquel que cubre la máxima cantidad de requisitos pendientes al menor costo posible.

\section{Descripción del Algoritmo Greedy}

\subsection{Estrategia General}

El algoritmo greedy para el problema de cobertura de habilidades sigue el patrón clásico de los algoritmos greedy:

\begin{enumerate}
    \item \textbf{Inicializar}: Comenzar con un conjunto vacío de empleados seleccionados
    \item \textbf{Iterar}: Mientras existan requerimientos no cubiertos:
    \begin{enumerate}
        \item Calcular la eficiencia de cada empleado disponible
        \item Seleccionar el empleado con máxima eficiencia
        \item Agregarlo al conjunto de seleccionados
        \item Actualizar los requerimientos pendientes
    \end{enumerate}
    \item \textbf{Terminar}: Cuando no hay más requerimientos o no hay empleados útiles
\end{enumerate}

\subsection{Función de Eficiencia}

\begin{definition}[Eficiencia de un Empleado]

Para un empleado $e_i$ y un conjunto de requerimientos no cubiertos $U$, la eficiencia se define como:

\[
\text{eficiencia}(e_i, U) = \frac{|\{r \in U : e_i \text{ puede cubrir } r\}|}{c_i}
\]

donde $c_i$ es el costo (salario por hora) del empleado $e_i$.

Esta métrica cuantifica cuántos requerimientos pendientes puede cubrir por unidad de costo.

\end{definition}

La función de eficiencia favorece:
\begin{itemize}
    \item Empleados que cubren muchos requerimientos (numerador grande)
    \item Empleados de bajo costo (denominador pequeño)
\end{itemize}

\subsection{Pseudocódigo}

\begin{algorithm}[H]
\caption{Algoritmo Greedy para Selección de Talento}
\begin{algorithmic}[1]
\Function{Greedy}{$\text{employees}, \text{requirements}$}
    \State $\text{selected} \gets \emptyset$
    \State $\text{available} \gets \text{employees}$
    \State $\text{uncovered} \gets \text{requirements}$
    \State $\text{total\_cost} \gets 0$
    
    \While{$\text{uncovered} \neq \emptyset$ \textbf{and} $\text{available} \neq \emptyset$}
        \State $\text{best\_employee} \gets \text{nil}$
        \State $\text{best\_efficiency} \gets 0$
        
        \For{\textbf{each} $e \in \text{available}$}
            \State $\text{coverage} \gets |\{r \in \text{uncovered} : e \text{ cubre } r\}|$
            \If{$\text{coverage} > 0$}
                \State $\text{eff} \gets \frac{\text{coverage}}{c_e}$
                \If{$\text{eff} > \text{best\_efficiency}$}
                    \State $\text{best\_employee} \gets e$
                    \State $\text{best\_efficiency} \gets \text{eff}$
                \EndIf
            \EndIf
        \EndFor
        
        \If{$\text{best\_employee} = \text{nil}$}
            \State \textbf{break}
        \EndIf
        
        \State $\text{selected.add}(\text{best\_employee})$
        \State $\text{available.remove}(\text{best\_employee})$
        \State $\text{total\_cost} \gets \text{total\_cost} + c_{\text{best\_employee}}$
        
        \State \textbf{for each} $r \in \text{uncovered}$ \textbf{where} $\text{best\_employee cubre } r$:
        \State \quad $\text{uncovered.remove}(r)$
    \EndWhile
    
    \State $\text{is\_valid} \gets (\text{uncovered} = \emptyset)$
    \State \textbf{return} Solution($\text{selected}, \text{total\_cost}, \text{is\_valid}$)
\EndFunction
\end{algorithmic}
\end{algorithm}

\section{Análisis Teórico del Algoritmo}

\subsection{Garantía de Aproximación}

\begin{theorem}[Garantía de Aproximación del Greedy para Weighted Set Cover]

Sea $C^*$ el costo óptimo de una solución válida para el problema de cobertura de habilidades ponderado, y $C_G$ el costo de la solución greedy.

Si la solución greedy es válida (cubre todos los requerimientos), entonces:

\[
C_G \leq C^* \cdot H(m)
\]

donde $H(m) = 1 + \frac{1}{2} + \frac{1}{3} + \ldots + \frac{1}{m}$ es el $m$-ésimo número armónico, y $m = |R|$ es el número de requerimientos.

\end{theorem}

\begin{proof}

La demostración utiliza el análisis de la ganancia marginal. En cada iteración $i$, el greedy selecciona un empleado que maximiza la razón:

\[
\text{ganancia\_marginal}_i = \frac{\text{requerimientos nuevos cubiertos}}{\text{costo del empleado}}
\]

Sea $r_i$ el número de requerimientos no cubiertos después de $i$ iteraciones. Por construcción del greedy:

\[
r_i \leq r_{i-1} - \frac{r_{i-1}}{H(m)}
\]

Esto implica:

\[
r_i \leq r_0 \cdot \left(1 - \frac{1}{H(m)}\right)^i
\]

Integrando sobre el número de iteraciones y utilizando el hecho de que el costo óptimo debe cubrir al menos $\frac{r_{i-1}}{H(m)}$ requerimientos en cada iteración:

\[
C_G = \sum_{i=1}^{k} c_i \leq C^* \cdot H(m)
\]

donde $k$ es el número de empleados seleccionados.

\end{proof}

\begin{corollary}[Implicaciones Prácticas]

Para problemas con:
\begin{itemize}
    \item $m = 5$ requerimientos: $H(5) \approx 2.28$, es decir, el greedy produce una solución a lo sumo 2.28 veces más cara que la óptima
    \item $m = 10$ requerimientos: $H(10) \approx 2.93$
    \item $m = 20$ requerimientos: $H(20) \approx 3.60$
\end{itemize}

Nótese que el número armónico crece logarítmicamente, lo que hace que la garantía de aproximación sea razonablemente fuerte incluso para problemas grandes.

\end{corollary}

\subsection{Tightness de la Garantía}

\begin{proposition}[Ejemplos donde Greedy es Subóptimo]

Existen instancias del problema donde el algoritmo greedy produce soluciones significativamente más costosas que la óptima.

\end{proposition}

\begin{proof}[Contraejemplo]

Considérese una instancia con 4 requerimientos $\{r_1, r_2, r_3, r_4\}$ y empleados:

\begin{itemize}
    \item $e_1$: costo 100, cubre $\{r_1, r_2, r_3, r_4\}$ (todas las habilidades)
    \item $e_2$: costo 50.1, cubre $\{r_1, r_2\}$ (primera mitad)
    \item $e_3$: costo 50.1, cubre $\{r_3, r_4\}$ (segunda mitad)
\end{itemize}

Análisis de eficiencia:
\begin{itemize}
    \item $e_1$: eficiencia = $\frac{4}{100} = 0.04$
    \item $e_2$: eficiencia = $\frac{2}{50.1} \approx 0.040$
    \item $e_3$: eficiencia = $\frac{2}{50.1} \approx 0.040$
\end{itemize}

El algoritmo greedy selecciona $e_1$ (o arbitrariamente $e_2$ o $e_3$). Si selecciona $e_1$, costo greedy = 100.

La solución óptima es seleccionar $e_2$ y $e_3$, con costo = $50.1 + 50.1 = 100.2$.

En este caso, el greedy es casi óptimo. Sin embargo, con costos ajustados, se pueden construir ejemplos donde el greedy es significativamente peor.

\end{proof}

\section{Correctitud de la Solución Greedy}

\begin{theorem}[Validez de la Solución Greedy]

Si el algoritmo greedy retorna una solución válida (is\_valid = True), entonces esa solución efectivamente cubre todos los requerimientos del cliente.

\end{theorem}

\begin{proof}

La solución greedy es válida si y solo si al terminar, el conjunto $\text{uncovered}$ de requerimientos está vacío.

Por construcción del algoritmo:
\begin{enumerate}
    \item Los requerimientos se marcan como cubiertos únicamente cuando un empleado seleccionado puede satisfacerlos
    \item Un empleado es seleccionado si y solo si puede cubrir al menos un requerimiento pendiente
    \item El algoritmo termina cuando no hay más requerimientos pendientes
\end{enumerate}

Por lo tanto, una solución válida garantiza que cada requerimiento $r \in R$ ha sido cubierto por al menos un empleado seleccionado $e \in \text{selected}$ que posee la habilidad requerida con el nivel mínimo.

\end{proof}

\begin{theorem}[Completitud del Algoritmo]

El algoritmo greedy siempre termina en un número finito de pasos.

\end{theorem}

\begin{proof}

En cada iteración, sucede una de dos cosas:

\begin{enumerate}
    \item Se selecciona un empleado y se agrega a $\text{selected}$, reduciendo $\text{available}$
    \item No hay empleado que cumpla la condición, y el algoritmo termina
\end{enumerate}

Como $\text{available}$ es finito y solo disminuye, el algoritmo termina en a lo sumo $n$ iteraciones, donde $n = |E|$ es el número de empleados.

\end{proof}

\section{Análisis de Complejidad}

\subsection{Complejidad Temporal}

\begin{theorem}[Complejidad Temporal del Algoritmo Greedy]

La complejidad temporal del algoritmo greedy es $O(n^2 \cdot m)$, donde $n = |E|$ es el número de empleados y $m = |R|$ es el número de requerimientos.

\end{theorem}

\begin{proof}

Desglosamos el análisis en partes:

\textbf{Estructura del bucle principal:}

El bucle while externo itera a lo sumo $n$ veces (seleccionar a lo sumo $n$ empleados).

\textbf{Trabajo por iteración:}

En cada iteración:

\begin{enumerate}
    \item \textbf{Búsqueda del mejor empleado}: Para cada empleado $e \in \text{available}$
    \begin{itemize}
        \item Calcular cobertura de $e$ sobre requerimientos no cubiertos: $O(m)$ (iterar sobre $m$ requerimientos)
        \item Comparar eficiencia: $O(1)$
        \item Total por empleado: $O(m)$
    \end{itemize}
    
    En esta etapa revisamos a lo sumo $n$ empleados, resultando en $O(n \cdot m)$ por iteración.
    
    \item \textbf{Actualización de requerimientos no cubiertos}: 
    \begin{itemize}
        \item Iterar sobre requerimientos cubiertos por el empleado seleccionado: $O(m)$
    \end{itemize}
\end{enumerate}

\textbf{Complejidad total:}

\[
T(n, m) = n \text{ iteraciones} \times O(n \cdot m) \text{ por iteración} = O(n^2 \cdot m)
\]

\end{proof}

\subsubsection{Análisis Detallado por Caso}

\begin{itemize}
    \item \textbf{Mejor caso}: $O(m)$ si el primer empleado cubre todos los requerimientos
    \item \textbf{Caso promedio}: $O(n \cdot m \cdot k)$ donde $k$ es el número promedio de empleados seleccionados (típicamente $k \ll n$)
    \item \textbf{Peor caso}: $O(n^2 \cdot m)$ cuando es necesario iterar sobre todos los empleados
\end{itemize}

\subsection{Complejidad Espacial}

\begin{theorem}[Complejidad Espacial]

La complejidad espacial del algoritmo greedy es $O(n + m)$.

\end{theorem}

\begin{proof}

Las estructuras de datos utilizadas son:

\begin{enumerate}
    \item $\text{selected}$: conjunto de empleados seleccionados, tamaño $O(n)$
    \item $\text{available}$: conjunto de empleados disponibles, tamaño $O(n)$
    \item $\text{uncovered}$: diccionario de requerimientos no cubiertos, tamaño $O(m)$
    \item Variables escalares: $O(1)$
\end{enumerate}

Total: $O(n) + O(n) + O(m) = O(n + m)$

\end{proof}

\subsection{Tabla Comparativa de Complejidad}

\begin{center}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Métrica} & \textbf{Greedy} & \textbf{Backtracking} & \textbf{DP} \\
\hline
Mejor caso & $O(m)$ & $O(n \cdot m)$ & $O(n \cdot 2^m)$ \\
Caso promedio & $O(k \cdot n \cdot m)$ & $O(c^n \cdot n \cdot m)$ & $O(n \cdot 2^m)$ \\
Peor caso & $O(n^2 \cdot m)$ & $O(2^n \cdot n \cdot m)$ & $O(n \cdot 2^m)$ \\
Espacio & $O(n + m)$ & $O(n + m)$ & $O(2^m)$ \\
\hline
\textbf{Garantía} & Aproximación & Óptima & Óptima \\
\hline
\end{tabular}
\end{center}

\section{Comparación con Otros Algoritmos}

\subsection{Greedy vs. Backtracking}

\begin{itemize}
    \item \textbf{Velocidad}: Greedy es mucho más rápido ($O(n^2 \cdot m)$ vs $O(2^n)$)
    \item \textbf{Optimalidad}: Backtracking garantiza solución óptima, greedy no
    \item \textbf{Escalabilidad}: Greedy es viable para instancias grandes, backtracking es limitado a ~16-20 empleados
    \item \textbf{Garantía}: Greedy tiene garantía de aproximación logarítmica
\end{itemize}

\subsection{Greedy vs. Programación Dinámica}

\begin{itemize}
    \item \textbf{Velocidad}: Greedy es más rápido cuando $m$ es grande ($O(n^2 \cdot m)$ vs $O(n \cdot 2^m)$)
    \item \textbf{Optimalidad}: DP garantiza solución óptima, greedy no
    \item \textbf{Espacio}: DP requiere $O(2^m)$, greedy requiere $O(n + m)$
    \item \textbf{Escalabilidad}: Greedy es mejor para muchos requerimientos, DP es mejor para pocos requerimientos
\end{itemize}

\section{Comportamiento en Instancias Prácticas}

\subsection{Fortalezas del Algoritmo Greedy}

\begin{enumerate}
    \item \textbf{Velocidad}: Complejidad polinomial permite procesar instancias muy grandes
    \item \textbf{Simplicidad}: Fácil de implementar y entender
    \item \textbf{Garantía teórica}: Factor de aproximación logarítmico conocido
    \item \textbf{Escalabilidad}: No sufre con instancias grandes
    \item \textbf{Determinismo}: Siempre produce el mismo resultado para las mismas entradas
\end{enumerate}

\subsection{Debilidades del Algoritmo Greedy}

\begin{enumerate}
    \item \textbf{Suboptimalidad}: Puede perder soluciones significativamente mejores
    \item \textbf{Falta de visión global}: Decisiones locales óptimas no garantizan solución global óptima
    \item \textbf{Casos patológicos}: Existen instancias donde la solución es cercana al factor de aproximación teórico
    \item \textbf{Sensibilidad a costos}: Empleados similares en habilidades pero con costos muy diferentes pueden llevar a malas elecciones
\end{enumerate}

\section{Mejoras Posibles al Algoritmo Greedy}

\subsection{Función de Eficiencia Alternativa}

Se pueden considerar variaciones en la métrica de eficiencia:

\begin{definition}[Eficiencia Ponderada]

\[
\text{eficiencia\_ponderada}(e_i, U) = \frac{\sum_{r \in U_i} w(r)}{c_i}
\]

donde $U_i$ es el conjunto de requerimientos no cubiertos que $e_i$ puede cubrir, y $w(r)$ es un peso asociado al requerimiento $r$ (ej: criticidad del requisito).

\end{definition}

Esta variante permite priorizar ciertos requerimientos sobre otros.

\subsection{Combinación con Búsqueda Local}

Una mejora práctica es ejecutar el greedy y luego aplicar optimizaciones de búsqueda local:

\begin{enumerate}
    \item Ejecutar el greedy para obtener una solución inicial
    \item Intentar remover empleados cuya cobertura puede ser reemplazada por otros más baratos
    \item Iterar hasta que no haya mejoras posibles
\end{enumerate}

Esta estrategia es denominada \textbf{Greedy + Local Search} y puede mejorar significativamente la solución sin incrementar demasiado el tiempo.

\section{Validación Experimental}

\subsection{Hipótesis de Prueba}

En instancias prácticas del problema TalentBridge Connect:

\begin{enumerate}
    \item El algoritmo greedy produce soluciones válidas en la mayoría de los casos
    \item El costo de las soluciones greedy está típicamente dentro del 10-20\% del óptimo
    \item La velocidad del greedy es mucho mayor que backtracking, permitiendo procesamiento interactivo
\end{enumerate}

\subsection{Comparación Empírica}

De acuerdo con los experimentos documentados en \texttt{project.ipynb}:

\begin{itemize}
    \item \textbf{Tasa de validez}: Comparable o superior a backtracking en instancias donde existe solución
    \item \textbf{Tiempos de ejecución}: Típicamente 10-100x más rápido que backtracking
    \item \textbf{Calidad de soluciones}: En promedio 5-15\% más costoso que backtracking (óptimo)
    \item \textbf{Consistencia}: Varianza en costos similar a otros algoritmos
\end{itemize}

\section{Conclusiones}

\begin{enumerate}
    \item El algoritmo \textbf{Greedy} es un algoritmo de aproximación con complejidad temporal polinomial $O(n^2 \cdot m)$
    
    \item Proporciona una \textbf{garantía de aproximación logarítmica} de $H(m)$, lo que significa que la solución es a lo sumo $H(m)$ veces más cara que la óptima
    
    \item Es \textbf{ideal para aplicaciones de tiempo real} donde se necesita una solución rápida y razonable, en lugar de la solución óptima
    
    \item La complejidad espacial $O(n + m)$ lo hace viable incluso para instancias con miles de empleados y requerimientos
    
    \item En la práctica, la brecha entre la solución greedy y la óptima es significativamente menor que el factor de aproximación teórico
    
    \item Para maximizar calidad, puede combinarse con técnicas de búsqueda local o usarse como solución inicial para otros algoritmos
    
    \item La elección entre Greedy, Backtracking y DP debe basarse en:
    \begin{itemize}
        \item \textbf{Tiempo disponible}: Greedy si es crítico, Backtracking/DP si hay tiempo
        \item \textbf{Tamaño del problema}: Greedy para instancias grandes, otros para pequeñas
        \item \textbf{Calidad requerida}: Greedy si la aproximación es aceptable, otros para optimalidad
        \item \textbf{Número de requerimientos}: DP si $m \leq 20$, greedy si $m$ es grande
    \end{itemize}
\end{enumerate}

\end{document}